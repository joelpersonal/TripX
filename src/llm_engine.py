import requests
import json
from typing import Dict, List, Optional
import os
from datetime import datetime, timedelta


class FreeLLMEngine:
    """
    LLM Engine using free APIs for text generation.
    
    Note: ML makes decisions, LLM only generates text.
    """
    
    def __init__(self, provider: str = "groq"):
        self.provider = provider
        self.setup_llm_client()
    
    def setup_llm_client(self):
        """Setup free LLM client"""
        if self.provider == "groq":
            # Groq API (free tier)
            self.api_key = os.getenv('GROQ_API_KEY', 'demo_key')
            self.base_url = "https://api.groq.com/openai/v1/chat/completions"
            self.model = "llama3-8b-8192"
        
        elif self.provider == "huggingface":
            self.api_key = os.getenv('HF_API_KEY', 'demo_key')
            self.base_url = "https://api-inference.huggingface.co/models/microsoft/DialoGPT-large"
            self.model = "microsoft/DialoGPT-large"
        
        elif self.provider == "ollama":
            self.base_url = "http://localhost:11434/api/generate"
            self.model = "llama2"
            self.api_key = None
    
    def generate_text(self, prompt: str, max_tokens: int = 500) -> str:
        """Generate text using free LLM API - only for text, not decisions."""
        try:
            if self.api_key == 'demo_key':
                return self._mock_llm_response(prompt)
            
            if self.provider == "groq":
                return self._call_groq_api(prompt, max_tokens)
            elif self.provider == "huggingface":
                return self._call_huggingface_api(prompt, max_tokens)
            elif self.provider == "ollama":
                return self._call_ollama_api(prompt, max_tokens)
        
        except Exception as e:
            return f"LLM generation failed: {str(e)}. Using fallback text generation."
    
    def _call_groq_api(self, prompt: str, max_tokens: int) -> str:
        """Call Groq API (LLaMA-3)"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": 0.7
        }
        
        response = requests.post(self.base_url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            return data['choices'][0]['message']['content']
        else:
            raise Exception(f"Groq API error: {response.status_code}")
    
    def _call_huggingface_api(self, prompt: str, max_tokens: int) -> str:
        """Call Hugging Face Inference API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": max_tokens,
                "temperature": 0.7,
                "return_full_text": False
            }
        }
        
        response = requests.post(self.base_url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            return data[0]['generated_text']
        else:
            raise Exception(f"HuggingFace API error: {response.status_code}")
    
    def _call_ollama_api(self, prompt: str, max_tokens: int) -> str:
        """Call local Ollama API"""
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_predict": max_tokens,
                "temperature": 0.7
            }
        }
        
        response = requests.post(self.base_url, json=payload, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            return data['response']
        else:
            raise Exception(f"Ollama API error: {response.status_code}")
    
    def _mock_llm_response(self, prompt: str) -> str:
        """Mock LLM response for demo purposes"""
        if "itinerary" in prompt.lower():
            return 
        
        elif "explanation" in prompt.lower():
            return "This destination was recommended because it perfectly matches your preferences for culture and adventure, fits within your budget range, and offers the ideal trip duration you're looking for. The combination of rich history, vibrant local culture, and excellent safety ratings makes it an outstanding choice for your travel style."
        
        else:
            return "This is a demo response from the LLM engine. In production, this would be generated by a real language model."


class FreeAPIIntegrator:
    
    def __init__(self):
        self.weather_base_url = "https://api.open-meteo.com/v1/forecast"
        self.places_base_url = "https://api.opentripmap.com/0.1/en/places"
        self.opentripmap_key = os.getenv('OPENTRIPMAP_KEY', 'demo_key')
    
    def get_weather_data(self, latitude: float, longitude: float) -> Dict:
        """Get weather data using Open-Meteo (free, no API key needed)"""
        try:
            params = {
                'latitude': latitude,
                'longitude': longitude,
                'current_weather': 'true',
                'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum',
                'forecast_days': 7
            }
            
            response = requests.get(self.weather_base_url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    'current_temp': data['current_weather']['temperature'],
                    'weather_code': data['current_weather']['weathercode'],
                    'daily_forecast': data['daily'],
                    'status': 'success'
                }
        
        except Exception as e:
            return self._mock_weather_data()
        
        return self._mock_weather_data()
    
    def get_attractions(self, latitude: float, longitude: float, radius: int = 5000) -> List[Dict]:
        """Get attractions using OpenTripMap (free tier available)"""
        try:
            if self.opentripmap_key == 'demo_key':
                return self._mock_attractions_data()
            
            params = {
                'radius': radius,
                'lon': longitude,
                'lat': latitude,
                'kinds': 'cultural,natural,historic,museums',
                'format': 'json',
                'limit': 10,
                'apikey': self.opentripmap_key
            }
            
            response = requests.get(f"{self.places_base_url}/radius", params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return [
                    {
                        'name': place.get('name', 'Unknown'),
                        'category': place.get('kinds', '').split(',')[0],
                        'distance': place.get('dist', 0)
                    }
                    for place in data.get('features', [])[:5]
                ]
        
        except Exception as e:
            return self._mock_attractions_data()
        
        return self._mock_attractions_data()
    
    def _mock_weather_data(self) -> Dict:
        """Mock weather data for demo"""
        import random
        return {
            'current_temp': round(random.uniform(15, 28), 1),
            'weather_code': random.choice([0, 1, 2, 3]),  # 0=clear, 1=partly cloudy, etc.
            'daily_forecast': {
                'temperature_2m_max': [random.randint(20, 30) for _ in range(7)],
                'temperature_2m_min': [random.randint(10, 20) for _ in range(7)]
            },
            'status': 'success'
        }
    
    def _mock_attractions_data(self) -> List[Dict]:
        """Mock attractions data for demo"""
        return [
            {'name': 'Historic City Center', 'category': 'historic', 'distance': 500},
            {'name': 'National Museum', 'category': 'museums', 'distance': 1200},
            {'name': 'Central Park', 'category': 'natural', 'distance': 800},
            {'name': 'Cultural Quarter', 'category': 'cultural', 'distance': 1500},
            {'name': 'Old Town Square', 'category': 'historic', 'distance': 600}
        ]


class TravelItineraryGenerator:
    
    def __init__(self, llm_provider: str = "groq"):
        self.llm_engine = FreeLLMEngine(llm_provider)
        self.api_integrator = FreeAPIIntegrator()
        
        # Coordinate mapping for major cities (in production, use geocoding API)
        self.city_coordinates = {
            'Paris': (48.8566, 2.3522),
            'Tokyo': (35.6762, 139.6503),
            'New York': (40.7128, -74.0060),
            'London': (51.5074, -0.1278),
            'Bangkok': (13.7563, 100.5018),
            'Rome': (41.9028, 12.4964),
            'Barcelona': (41.3851, 2.1734),
            'Sydney': (-33.8688, 151.2093),
            'Dubai': (25.2048, 55.2708),
            'Istanbul': (41.0082, 28.9784)
        }
    
    def generate_itinerary(self, user_preferences: Dict, ml_recommendations: List[Dict]) -> Dict:
        
        if not ml_recommendations:
            return {'error': 'No ML recommendations provided'}
        
        primary_destination = ml_recommendations[0]
        
        weather_data = self._get_destination_weather(primary_destination)
        attractions = self._get_destination_attractions(primary_destination)
        
        itinerary_text = self._generate_itinerary_text(user_preferences, primary_destination, attractions)
        
        explanation = self._generate_explanation_text(user_preferences, primary_destination)
        
        itinerary = {
            'destination': primary_destination,
            'user_preferences': user_preferences,
            'ml_score': primary_destination['overall_score'],
            'ml_explanation': primary_destination['explanation'],
            'weather_context': weather_data,
            'top_attractions': attractions,
            'daily_itinerary': itinerary_text,
            'llm_explanation': explanation,
            'alternative_destinations': ml_recommendations[1:3] if len(ml_recommendations) > 1 else [],
            'generated_at': datetime.now().isoformat()
        }
        
        return itinerary
    
    def _get_destination_weather(self, destination: Dict) -> Dict:
        """Get weather data for destination"""
        dest_name = destination['destination']
        coordinates = self.city_coordinates.get(dest_name, (0, 0))
        
        if coordinates != (0, 0):
            return self.api_integrator.get_weather_data(coordinates[0], coordinates[1])
        else:
            return self.api_integrator._mock_weather_data()
    
    def _get_destination_attractions(self, destination: Dict) -> List[Dict]:
        """Get attractions for destination"""
        dest_name = destination['destination']
        coordinates = self.city_coordinates.get(dest_name, (0, 0))
        
        if coordinates != (0, 0):
            return self.api_integrator.get_attractions(coordinates[0], coordinates[1])
        else:
            return self.api_integrator._mock_attractions_data()
    
    def _generate_itinerary_text(self, user_prefs: Dict, destination: Dict, attractions: List[Dict]) -> str:
        """Generate day-wise itinerary using LLM"""
        
        attractions_text = ", ".join([attr['name'] for attr in attractions[:3]])
        
        prompt = f"""Create a {user_prefs.get('duration', 7)}-day travel itinerary for {destination['destination']}, {destination['country']}.

Trip Details:
- Budget: ${user_prefs.get('budget', 100)}/day
- Trip Type: {user_prefs.get('trip_type', 'culture')}
- Season: {user_prefs.get('season', 'spring')}
- Top Attractions: {attractions_text}

Create a day-by-day itinerary with morning, afternoon, and evening activities. Keep it practical and budget-conscious."""

        return self.llm_engine.generate_text(prompt, max_tokens=600)
    
    def _generate_explanation_text(self, user_prefs: Dict, destination: Dict) -> str:
        """Generate explanation using LLM"""
        
        prompt = f"""Explain why {destination['destination']}, {destination['country']} is an excellent choice for this traveler:

Traveler Profile:
- Budget: ${user_prefs.get('budget', 100)}/day
- Duration: {user_prefs.get('duration', 7)} days
- Interests: {user_prefs.get('trip_type', 'culture')} travel
- Season: {user_prefs.get('season', 'spring')}

Destination Details:
- Cost: ${destination['cost_per_day']}/day
- Trip Type: {destination['trip_type']}
- Best Season: {destination['best_season']}
- ML Score: {destination['overall_score']:.3f}

Write a compelling 2-3 sentence explanation of why this is a perfect match."""

        return self.llm_engine.generate_text(prompt, max_tokens=200)


if __name__ == "__main__":
    # Test the LLM and API integration
    print(" Testing LLM & API Integration")
    print("=" * 50)
    
    generator = TravelItineraryGenerator("groq")  # Using Groq (free)
    
    user_prefs = {
        'budget': 80,
        'duration': 5,
        'trip_type': 'culture',
        'season': 'spring'
    }
    
    ml_recommendation = {
        'destination': 'Paris',
        'country': 'France',
        'region': 'Europe',
        'cost_per_day': 120,
        'trip_type': 'culture',
        'best_season': 'spring',
        'overall_score': 0.892,
        'explanation': 'Perfect match for culture travel with excellent museums and spring weather'
    }
    
    # Generate itinerary
    print("Generating itinerary...")
    itinerary = generator.generate_itinerary(user_prefs, [ml_recommendation])
    
    print(f"\nüìç Destination: {itinerary['destination']['destination']}")
    print(f" ML Score: {itinerary['ml_score']:.3f}")
    print(f"Weather: {itinerary['weather_context']['current_temp']}¬∞C")
    print(f"Top Attractions: {len(itinerary['top_attractions'])} found")
    
    print(f"\n LLM-Generated Itinerary:")
    print(itinerary['daily_itinerary'])
    
    print(f"\n LLM-Generated Explanation:")
    print(itinerary['llm_explanation'])
    
    print(f"\n Integration test complete!")
    print(f" Architecture: ML (decisions) + LLM (text) + APIs (enrichment)")